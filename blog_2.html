<!DOCTYPE html>
<html lang="en">
<head>
 <title>LabelBinarizer & LabelEncoder</title>
 <!-- Latest compiled and minified CSS -->
 <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">
 <div class="container">
  <h1><a href="https://codykane.github.io/blog">Blog</a></h1>
 </div>
</head>
<body>
 <div class="container">
<div class="row">
 <div class="col-md-8">
  <h3>LabelBinarizer & LabelEncoder</h3>
  <label>2019-07-04</label>
  <p>To avoid your machine learning model blowing up when you feed it data in production, it's necessary to give it numerical values, rather than categorical variables in the form of strings. There are a few different ways to go about this in your preprocessing flow, depending on whether the categories have relative weight, and whether the absolute values are important. </p>
<p>Code:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">LabelBinarizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="c1">##First we&#39;ll make our dataframe, with cities and their population(millions)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;city&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Barcelona&#39;</span><span class="p">,</span> <span class="s1">&#39;Paris&#39;</span><span class="p">,</span> <span class="s1">&#39;Shanghai&#39;</span><span class="p">,</span> <span class="s1">&#39;Barcelona&#39;</span><span class="p">,</span> <span class="s1">&#39;Cairo&#39;</span><span class="p">],</span> <span class="s1">&#39;pop&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.6</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">26.3</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span>
                                                                                                <span class="mf">19.5</span><span class="p">]})</span>

<span class="n">df</span>


<span class="c1">##To feed this into a machine learning algorithm, we&#39;ll need to convert the strings in the city column into integers</span>

<span class="c1">##LabelEncoder</span>
<span class="n">tp</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="n">LabelEncoder</span><span class="p">()),</span> <span class="p">(</span><span class="s1">&#39;pop&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)]</span>
<span class="n">mapper</span> <span class="o">=</span> <span class="n">DataFrameMapper</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">df_out</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">mapper</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1">##LabelBinarizer</span>
<span class="n">tp</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="n">LabelBinarizer</span><span class="p">()),</span> <span class="p">(</span><span class="s1">&#39;pop&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)]</span>
<span class="n">mapper</span> <span class="o">=</span> <span class="n">DataFrameMapper</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">df_out</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">mapper</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1">##Now let&#39;s assume we&#39;re just interested in the population relative to the other cities, and not their absolute values. LabelBinarizer will be useless here as the values are unique, but LabelEncoder will assign ranks to each of them, Barcelona being 0 as it has the smallest population.</span>

<span class="n">tp</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;pop&#39;</span><span class="p">,</span> <span class="n">LabelEncoder</span><span class="p">()),</span> <span class="p">(</span><span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)]</span>
<span class="n">mapper</span> <span class="o">=</span> <span class="n">DataFrameMapper</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">df_out</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">mapper</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>


<p>In the above blocks, it's necessary to use dataframemapper to only apply this to one column while keeping the others intact.  Take note that LabelEncoder will assign ascending values based on the alphabetical value of the strings, as seen in 'df' above, where Barcelona is 0, Cairo 1 etc. If the label is binary, like male/female, LabelEncoder will return zeroes and ones, which is preferable over LabelBinarizer due to it being one column, whereas Labelbinarizer would create two, one in which male is positive (1) and one where female is. LabelEnconder has another use, when categorical data has relative weight (ex: hate, dislike, neutral, like, love on a questionnaire) that needs to be encoded.  Otherwise, when the categories are unrelated, for example neighbourhoods, assigning one neighbourhood "a" 1 and neighbourhood "b" 2 can lead your algorithm to think that neighbourhood "b" = 2 * neighbourhood "a", which can cause a lot of problems. While the more common approach to convert categorical features into binary seems to be OneHotEncoder,  LabelBinarizer does exactly the same thing, and I've found that LabelBinarizer's implementation is marginally simpler. </p>
<p>For some other resources on how to implement LabelEncoder &amp; Label Binarizer, I recommend: </p>
<p>https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/</p>
<p>https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html</p>
<p>https://towardsdatascience.com/encoding-categorical-features-21a2651a065c</p>
 </div>
</div>
 </div>
</body>
</html>